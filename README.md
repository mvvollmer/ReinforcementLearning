# ReinforcementLearning
Collection of activities I've done from Sutton and Barto's Reinforcement Learning 2nd Edition 

# Interesting Results
## EX1:
### 10-Armed Bandit using Epsilon-Greedy Algorithm with Incremental Update
Average Reward:

![EX1Fig1](ex1_fall24/Q5AverageReward(Best).png)

Optimal Action Percentage:

![EX1Fig2](ex1_fall24/Q5OptimalAction(Best).png)

### Epsilon-Greedy Algorithm with optimistic initial values and the bandit algorithm with UCB action selection.
Average Reward:

![EX1Fig3](ex1_fall24/Q6AverageReward.png)

Optimal Action Percentage:

![EX1Fig3](ex1_fall24/Q6OptimalAction(Best).png)

## EX3:
### Solving Jacks Car Rental Problem with Policy Iteration
Normal Jack's Car Rental Problem:

![EX3Fig1](ex3_fall24/jacknonmod.png)

Modified Jack's Car Rental Problem:

![EX3Fig2](ex3_fall24/JacksCarProb.png)


## EX4:
### Optimal Blackjack policy found using first-visit Monte-Carlo control with exploring starts (Monte-Carlo ES)
Non-Useable Ace:

![EX4Fig1](ex4_fall24/2bplot2.png)

Useable Ace:

![EX4Fig1](ex4_fall24/2bplot4.png)


## EX5:
### Comparing SARSA (on-policy TD control), Expected SARSA, and Q-learning (off-policy TD control) on Windy GridWorld

![EX5Fig1](ex5_fall24/Q4aFig.png)


## EX6:
### Dyna Q on Blocked Maze (the path through the maze is blocked halfway through and a new opening appears).

![EX6Fig1](ex6_fall24/fig8.4.png)

Dyna Q on ShortCut Maze (a more optimal path opens halfway through).

![EX6Fig2](ex6_fall24/fig8.5.png)
